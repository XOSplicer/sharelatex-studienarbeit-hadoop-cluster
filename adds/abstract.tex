% !TEX root = ../master.tex
\chapter*{Abstract}

\begingroup
  \begin{table}[h!]
    \setlength\tabcolsep{0pt}
    \begin{tabular}{p{3.5cm}p{11.9cm}}
      Title & \dertitel \\
      Author: & \derautor \\
    \end{tabular}
  \end{table}
\endgroup

\hspace{2cm}

The ever-increasing amount of data available in the current digital age 
poses major challenges for corporations, a phenomenon widely known as \emph{Big Data}. 
In order to leverage insight from this data, 
one needs to have information systems in place providing a platform for Data Analysts resp. 
Data Scientists to analyze the data in an efficient manner. 
This field of work is usually consolidated under the term \acf{BIA}.

As the computing power of each computer is limited by both physical as well as economic constraints, 
the scale of nowadays' Big Data cannot be handled by 
\enquote{simple} monolithic information systems operating on singular machines. 
Instead, a multitude of machines have to be connected in order to form \emph{computing clusters}. 
Such cluster environments can scale with the increasing amount of data managed by it. 
The various nodes of each cluster have to be organized,
e.g. by assigning tasks to a particular machine or sending data to places where it is needed. 
This work is performed by so-called \emph{cluster managers}.

A popular cluster manager for Big Data clusters in the industry is the \emph{Hadoop} framework. 
Hadoop offers distributed storage for arbitrary-sized collections of data by combining the individual computing and storage resources of commodity hardware. 
Furthermore, it provides programming interfaces for interacting with and analyzing the stored data.

This research project is embedded into a larger body of investigation 
regarding the aptitude of Hadoop as \acs{BIA} information system for use at the \acf{DHBW} in both research and administration. 
Thus, this work specifically deals with the following topics:

\begin{itemize}
    \item Examine existing infrastructure
    \item 
\end{itemize}


