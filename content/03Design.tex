% !TEX root = ../master.tex
\chapter{Design and Methodology}
\label{chap:design}

\section{Analysis of Cluster Environment and Requirements}

TODO

\section{Research on Possibilities}

After the requirements are settled,
the possibilities of how Hadoop can actually be installed 
on the given infrastructure will be researched.

There are four ways to install Hadoop that are considered here:

\begin{itemize}
    \item A \emph{manual installation} of Hadoop 
        and every additional piece of software frrm the ecosystem
    \item \emph{\ac{CDH}} --  An open source software distribution by Cloudera including Hadoop
        and additional software from the ecosystem
    \item \emph{Ambari} -- An open source project by Apache that provides
        the capability to manage Hadoop Clusters and the software components running on it.
    \item \emph{\ac{HDP}} -- Hortonswork's ready-to-install distribution of Hadoop 
        with Ambari and additional software
\end{itemize}

Since \ac{HDP} makes use of Ambari for installing the cluster and managing the installed software while it simply provides a pre-packaged version of the components, 
it can be preferred over using Ambari directly which would create the need to compile it from source.

In the coming sections each of those three resulting possibilities will be looked at in more detail.
For each of the options an evaluation will be made on whether it is 
feasible to deploy an Hadoop installation with the methods that they provide.
Therefore a simple test installation in an OpenStack environment is made.
For this purpose the OpenStack environment \emph{BWCloud}\footnote{www.bw-cloud.org} is used, an environment that is available for students at the \ac{DHBW} and other universities in Baden-WÃ¼rttemberg for educational purposes. It is generally an equivalent software to the actual cluster environment, however it is accessible from the internet, which makes it more comfortable to work with while performing the tests.

\subsection{Manual Installation of Hadoop}

Tom White\autocite[][Appendix A]{white2015hadoop} describes how Hadoop can be manually installed on the machines in an cluster. 
Manually here means without the help of automated installers for a single machine or the complete cluster. 
Every aspect of the installation and configuration must be done \enquote{by hand}.
White gives step by step instruction on the process.

For the installation two \acs{VM} are used, utilizing two virtual \ac{CPU} Cores and eight \ac{GB} \ac{RAM} and a 20 \ac{GB} storage drive. 
Ubuntu Server \footnote{https://www.ubuntu.com/server} 16.04.3 \ac{LTS} is used as the operating system. 
The machines are connected to the public internet and to each other using two network interfaces each.

The two machines are going to be connected together in an master-slave setup
where the master runs \ac{YARN} and the \ac{HDFS} name node aswell as an

TODO

\subsection{\acl{CDH}}

TODO

\subsection{\acl{HDP} with Apache Ambari}

TODO

\subsection{Decision on Distribution}

TODO

\section{Architecture Design}

TODO

\section{Execution Plan}

TODO
